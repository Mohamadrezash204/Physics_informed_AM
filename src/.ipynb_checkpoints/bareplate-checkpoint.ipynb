{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef936136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 18 17:17:32 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.00    Driver Version: 470.82.00    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:01:00.0 Off |                  Off |\n",
      "| 30%   49C    P8    43W / 300W |     10MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000    Off  | 00000000:2E:00.0 Off |                  Off |\n",
      "| 56%   79C    P0   113W / 300W |     10MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000    Off  | 00000000:41:00.0 Off |                  Off |\n",
      "| 35%   63C    P8    32W / 300W |  44382MiB / 48682MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A6000    Off  | 00000000:61:00.0 Off |                  Off |\n",
      "| 36%   63C    P8    47W / 300W |   1340MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     59189      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A     60559      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A     59189      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A     60559      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A     59189      G   /usr/lib/xorg/Xorg                 39MiB |\n",
      "|    2   N/A  N/A     60559      G   /usr/lib/xorg/Xorg                 78MiB |\n",
      "|    2   N/A  N/A     60715      G   /usr/bin/gnome-shell               22MiB |\n",
      "|    2   N/A  N/A    559783      C   /usr/bin/python3                44207MiB |\n",
      "|    3   N/A  N/A     59189      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A     60559      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A    561959      C   /usr/bin/python3                 1327MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6372c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import FNN\n",
    "from util import *\n",
    "from train import *\n",
    "from torch.autograd import Variable,grad\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd565de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_transform(X):\n",
    "    X = T_range*nn.Softplus()(X) + T_ref\n",
    "    return X\n",
    "\n",
    "\n",
    "def input_transform(X):\n",
    "    X = 2.*(X-X_min)/(X_max-X_min) - 1.\n",
    "    return X\n",
    "\n",
    "\n",
    "def PDE(x,y,z,t,net):\n",
    "    X = torch.concat([x,y,z,t],axis=-1)\n",
    "    T = net(X)\n",
    "    \n",
    "    T_t = grad(T,t,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "\n",
    "    T_x = grad(T,x,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "    T_xx = grad(T_x,x,create_graph=True,grad_outputs=torch.ones_like(T_x))[0]\n",
    "    \n",
    "    T_y = grad(T,y,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "    T_yy = grad(T_y,y,create_graph=True,grad_outputs=torch.ones_like(T_y))[0]\n",
    "    \n",
    "    T_z = grad(T,z,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "    T_zz = grad(T_z,z,create_graph=True,grad_outputs=torch.ones_like(T_z))[0]\n",
    "    \n",
    "    f = rho*Cp*T_t - k*(T_xx+T_yy+T_zz)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def generate_points(p=[],f=[]):\n",
    "\n",
    "    t = np.linspace(0,x_max[3],31)\n",
    "\n",
    "    # boundary points\n",
    "    bound_x_neg,_ = sampling_uniform(1.,x_min,x_max,'-x',t)\n",
    "    bound_x_pos,_ = sampling_uniform(1.,x_min,x_max,'+x',t)\n",
    "\n",
    "    bound_y_neg,_ = sampling_uniform(1.,x_min,x_max,'-y',t)\n",
    "    bound_y_pos,_ = sampling_uniform(1.,x_min,x_max,'+y',t)\n",
    "\n",
    "    bound_z_neg,_ = sampling_uniform(1.,x_min,x_max,'-z',t)\n",
    "    bound_z_pos,_ = sampling_uniform(1.,x_min,x_max,'+z',t)\n",
    "\n",
    "    bound_z_pos_more = [] # more points for surface flux\n",
    "    for ti in t:\n",
    "        if ti<t_end:\n",
    "            zi,_ = sampling_uniform(.25,\n",
    "                        [max(x0+ti*v-2*r,x_min[0]),max(x_min[1],y0-2*r),x_min[2]],\n",
    "                        [min(x0+ti*v+2*r,x_max[0]),min(x_max[1],y0+2*r),x_max[2]],\n",
    "                        '+z',[ti])\n",
    "            bound_z_pos_more.append(zi)\n",
    "\n",
    "    bound_z_pos_more = np.vstack(bound_z_pos_more)\n",
    "    bound_z_pos = np.vstack((bound_z_pos,bound_z_pos_more))\n",
    "\n",
    "    ### domain points\n",
    "    e = 0.05\n",
    "    domain_pts1,_ = sampling_uniform(2.,\n",
    "                                     [x_min[0]+e,x_min[1]+e,x_min[2]+e],\n",
    "                                     [x_max[0]-e,x_max[1]-e,x_max[2]-3.],'domain',t)\n",
    "\n",
    "    domain_pts2,_ = sampling_uniform(1.,\n",
    "                                     [x_min[0]+e,x_min[1]+e,x_max[2]-3.+e],\n",
    "                                     [x_max[0]-e,x_max[1]-e,x_max[2]-1.],'domain',t)\n",
    "\n",
    "    domain_pts3 = []\n",
    "    for ti in t:\n",
    "        di,_ = sampling_uniform(.5,\n",
    "                                [x_min[0]+e,x_min[1]+e,x_max[2]-1.+e,],\n",
    "                                [x_max[0]-e,x_max[1]-e,x_max[2]-e],'domain',[ti])\n",
    "        domain_pts3.append(di)\n",
    "    domain_pts3 = np.vstack(domain_pts3)\n",
    "    domain_pts = np.vstack((domain_pts1,domain_pts2,domain_pts3))\n",
    "\n",
    "    init_pts,_ = sampling_uniform(2.,[x_min[0],x_min[1],x_min[2]],\n",
    "                                   [x_max[0],x_max[1],x_max[2]],'domain',[0])\n",
    "\n",
    "    p.extend([torch.tensor(bound_x_neg,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(bound_x_pos,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(bound_y_neg,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(bound_y_pos,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(bound_z_neg,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(bound_z_pos,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(init_pts,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(domain_pts,requires_grad=True,dtype=torch.float).to(device)])\n",
    "    f.extend([['BC','-x'],['BC','+x'],['BC','-y'],['BC','+y'],['BC','-z'],['BC','+z'],['IC',T_ref],['domain']])\n",
    "    \n",
    "    return p,f\n",
    "\n",
    "\n",
    "def BC(x,y,z,t,loc,l=None):\n",
    "    X = torch.concat([x,y,z,t],axis=-1)\n",
    "    T = net(X)\n",
    "    if loc == '-x':\n",
    "        T_x = grad(T,x,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "        return k*T_x - h*T - Rboltz*emiss*T**4\n",
    "    if loc == '+x':\n",
    "        T_x = grad(T,x,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "        return -k*T_x - h*T - Rboltz*emiss*T**4\n",
    "    if loc == '-y':\n",
    "        T_y = grad(T,y,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "        return k*T_y - h*T - Rboltz*emiss*T**4\n",
    "    if loc == '+y':\n",
    "        T_y = grad(T,y,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "        return -k*T_y - h*T - Rboltz*emiss*T**4\n",
    "    if loc == '-z':\n",
    "        T_t = grad(T,t,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "        return T_t\n",
    "    if loc == '+z':\n",
    "        T_z = grad(T,z,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "        q = 2*P*eta/torch.pi/r**2*torch.exp(-2*(torch.square(x-x0-v*t)+torch.square(y-y0))/r**2)*(t<=t_end)\n",
    "        return -k*T_z - h*T + q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7537fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "task = 'bareplate'\n",
    "x_max = np.array([40., 10.,  6.,  3.])\n",
    "x_min = np.array([ 0.,  0.,  0.,  0.])\n",
    "X_max = torch.tensor(x_max,dtype=torch.float).to(device)\n",
    "X_min = torch.tensor(x_min,dtype=torch.float).to(device)\n",
    "\n",
    "T_ref = 298.\n",
    "T_range = 3000.\n",
    "\n",
    "Cp = 0.5\n",
    "k = 0.01\n",
    "\n",
    "x0 = 5. # laser start x\n",
    "y0 = 5.\n",
    "r = 1.5 # beam radius\n",
    "v = 10 # speed\n",
    "t_end = 3. # laser end time\n",
    "\n",
    "h = 2e-5\n",
    "eta = 0.4\n",
    "P = 500\n",
    "Rboltz = 5.6704e-14\n",
    "emiss = 0.3\n",
    "rho = 8e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb3044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,x_max[3],31)\n",
    "\n",
    "# boundary points\n",
    "bound_x_neg,_ = sampling_uniform(1.,x_min,x_max,'-x',t)\n",
    "bound_x_pos,_ = sampling_uniform(1.,x_min,x_max,'+x',t)\n",
    "\n",
    "bound_y_neg,_ = sampling_uniform(1.,x_min,x_max,'-y',t)\n",
    "bound_y_pos,_ = sampling_uniform(1.,x_min,x_max,'+y',t)\n",
    "\n",
    "bound_z_neg,_ = sampling_uniform(1.,x_min,x_max,'-z',t)\n",
    "bound_z_pos,_ = sampling_uniform(1.,x_min,x_max,'+z',t)\n",
    "\n",
    "bound_z_pos_more = [] # more points for surface flux\n",
    "for ti in t:\n",
    "    if ti<t_end:\n",
    "        zi,_ = sampling_uniform(.25,\n",
    "                    [max(x0+ti*v-2*r,x_min[0]),max(x_min[1],y0-2*r),x_min[2]],\n",
    "                    [min(x0+ti*v+2*r,x_max[0]),min(x_max[1],y0+2*r),x_max[2]],\n",
    "                    '+z',[ti])\n",
    "        bound_z_pos_more.append(zi)\n",
    "\n",
    "bound_z_pos_more = np.vstack(bound_z_pos_more)\n",
    "bound_z_pos = np.vstack((bound_z_pos,bound_z_pos_more))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e6ac462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, Loss: 1.631e+04, L_bc: 6.505e+04, L_ic: 1.837e+06, L_data: 0.000e+00, L_PDE: 5.176e+00, Time: 0.11\n",
      "It: 10, Loss: 6.756e+02, L_bc: 2.247e+03, L_ic: 4.554e+06, L_data: 0.000e+00, L_PDE: 2.131e-01, Time: 0.99\n",
      "It: 20, Loss: 5.833e+02, L_bc: 1.898e+03, L_ic: 4.350e+06, L_data: 0.000e+00, L_PDE: 2.222e-01, Time: 0.99\n",
      "It: 30, Loss: 1.920e+02, L_bc: 4.402e+02, L_ic: 3.279e+06, L_data: 0.000e+00, L_PDE: 8.218e-02, Time: 0.99\n",
      "It: 40, Loss: 1.724e+02, L_bc: 3.644e+02, L_ic: 3.251e+06, L_data: 0.000e+00, L_PDE: 7.240e-02, Time: 0.98\n",
      "It: 50, Loss: 1.079e+02, L_bc: 7.663e+01, L_ic: 3.549e+06, L_data: 0.000e+00, L_PDE: 1.418e-02, Time: 0.98\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-faf5a743dc63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpoint_sets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0ml_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPDE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpoint_sets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfo_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Physics_informed_AM/src/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, PDE, BC, point_sets, flags, iterations, lr, info_num)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml_BC\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml_IC\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml_PDE\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;31m#weighted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterations = 50000\n",
    "\n",
    "net = FNN([4,64,64,64,1],nn.Tanh(),in_tf=input_transform,out_tf=output_transform)\n",
    "net.to(device)\n",
    "\n",
    "point_sets,flags = generate_points([],[])\n",
    "\n",
    "l_history = train(net,PDE,BC,point_sets,flags,iterations,lr=5e-4,info_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474cc859",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'../model/{}.pt'.format(task))\n",
    "np.save('../model/{}.npy'.format(task),l_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea158c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
