{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef936136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 18 17:17:32 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.00    Driver Version: 470.82.00    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:01:00.0 Off |                  Off |\n",
      "| 30%   49C    P8    43W / 300W |     10MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000    Off  | 00000000:2E:00.0 Off |                  Off |\n",
      "| 56%   79C    P0   113W / 300W |     10MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000    Off  | 00000000:41:00.0 Off |                  Off |\n",
      "| 35%   63C    P8    32W / 300W |  44382MiB / 48682MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A6000    Off  | 00000000:61:00.0 Off |                  Off |\n",
      "| 36%   63C    P8    47W / 300W |   1340MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     59189      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A     60559      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A     59189      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A     60559      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A     59189      G   /usr/lib/xorg/Xorg                 39MiB |\n",
      "|    2   N/A  N/A     60559      G   /usr/lib/xorg/Xorg                 78MiB |\n",
      "|    2   N/A  N/A     60715      G   /usr/bin/gnome-shell               22MiB |\n",
      "|    2   N/A  N/A    559783      C   /usr/bin/python3                44207MiB |\n",
      "|    3   N/A  N/A     59189      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A     60559      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A    561959      C   /usr/bin/python3                 1327MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6372c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import FNN\n",
    "from util import *\n",
    "from train import *\n",
    "from torch.autograd import Variable,grad\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd565de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_transform(X):\n",
    "    X = T_range*nn.Softplus()(X) + T_ref\n",
    "    return X\n",
    "\n",
    "\n",
    "def input_transform(X):\n",
    "    X = 2.*(X-X_min)/(X_max-X_min) - 1.\n",
    "    return X\n",
    "\n",
    "\n",
    "def PDE(x,y,z,t,net):\n",
    "    X = torch.concat([x,y,z,t],axis=-1)\n",
    "    T = net(X)\n",
    "    \n",
    "    T_t = grad(T,t,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "\n",
    "    T_x = grad(T,x,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "    T_xx = grad(T_x,x,create_graph=True,grad_outputs=torch.ones_like(T_x))[0]\n",
    "    \n",
    "    T_y = grad(T,y,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "    T_yy = grad(T_y,y,create_graph=True,grad_outputs=torch.ones_like(T_y))[0]\n",
    "    \n",
    "    T_z = grad(T,z,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "    T_zz = grad(T_z,z,create_graph=True,grad_outputs=torch.ones_like(T_z))[0]\n",
    "    \n",
    "    f = rho*Cp*T_t - k*(T_xx+T_yy+T_zz)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def generate_points(p=[],f=[]):\n",
    "\n",
    "    t = np.linspace(0,x_max[3],31)\n",
    "\n",
    "    # boundary points\n",
    "    bound_x_neg,_ = sampling_uniform(1.,x_min,x_max,'-x',t)\n",
    "    bound_x_pos,_ = sampling_uniform(1.,x_min,x_max,'+x',t)\n",
    "\n",
    "    bound_y_neg,_ = sampling_uniform(1.,x_min,x_max,'-y',t)\n",
    "    bound_y_pos,_ = sampling_uniform(1.,x_min,x_max,'+y',t)\n",
    "\n",
    "    bound_z_neg,_ = sampling_uniform(1.,x_min,x_max,'-z',t)\n",
    "    bound_z_pos,_ = sampling_uniform(1.,x_min,x_max,'+z',t)\n",
    "\n",
    "    bound_z_pos_more = [] # more points for surface flux\n",
    "    for ti in t:\n",
    "        if ti<t_end:\n",
    "            zi,_ = sampling_uniform(.25,\n",
    "                        [max(x0+ti*v-2*r,x_min[0]),max(x_min[1],y0-2*r),x_min[2]],\n",
    "                        [min(x0+ti*v+2*r,x_max[0]),min(x_max[1],y0+2*r),x_max[2]],\n",
    "                        '+z',[ti])\n",
    "            bound_z_pos_more.append(zi)\n",
    "\n",
    "    bound_z_pos_more = np.vstack(bound_z_pos_more)\n",
    "    bound_z_pos = np.vstack((bound_z_pos,bound_z_pos_more))\n",
    "\n",
    "    ### domain points\n",
    "    e = 0.05\n",
    "    domain_pts1,_ = sampling_uniform(2.,\n",
    "                                     [x_min[0]+e,x_min[1]+e,x_min[2]+e],\n",
    "                                     [x_max[0]-e,x_max[1]-e,x_max[2]-3.],'domain',t)\n",
    "\n",
    "    domain_pts2,_ = sampling_uniform(1.,\n",
    "                                     [x_min[0]+e,x_min[1]+e,x_max[2]-3.+e],\n",
    "                                     [x_max[0]-e,x_max[1]-e,x_max[2]-1.],'domain',t)\n",
    "\n",
    "    domain_pts3 = []\n",
    "    for ti in t:\n",
    "        di,_ = sampling_uniform(.5,\n",
    "                                [x_min[0]+e,x_min[1]+e,x_max[2]-1.+e,],\n",
    "                                [x_max[0]-e,x_max[1]-e,x_max[2]-e],'domain',[ti])\n",
    "        domain_pts3.append(di)\n",
    "    domain_pts3 = np.vstack(domain_pts3)\n",
    "    domain_pts = np.vstack((domain_pts1,domain_pts2,domain_pts3))\n",
    "\n",
    "    init_pts,_ = sampling_uniform(2.,[x_min[0],x_min[1],x_min[2]],\n",
    "                                   [x_max[0],x_max[1],x_max[2]],'domain',[0])\n",
    "\n",
    "    p.extend([torch.tensor(bound_x_neg,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(bound_x_pos,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(bound_y_neg,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(bound_y_pos,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(bound_z_neg,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(bound_z_pos,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(init_pts,requires_grad=True,dtype=torch.float).to(device),\n",
    "              torch.tensor(domain_pts,requires_grad=True,dtype=torch.float).to(device)])\n",
    "    f.extend([['BC','-x'],['BC','+x'],['BC','-y'],['BC','+y'],['BC','-z'],['BC','+z'],['IC',T_ref],['domain']])\n",
    "    \n",
    "    return p,f\n",
    "\n",
    "\n",
    "def BC(x,y,z,t,loc,l=None):\n",
    "    X = torch.concat([x,y,z,t],axis=-1)\n",
    "    T = net(X)\n",
    "    if loc == '-x':\n",
    "        T_x = grad(T,x,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "        return k*T_x - h*T - Rboltz*emiss*T**4\n",
    "    if loc == '+x':\n",
    "        T_x = grad(T,x,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "        return -k*T_x - h*T - Rboltz*emiss*T**4\n",
    "    if loc == '-y':\n",
    "        T_y = grad(T,y,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "        return k*T_y - h*T - Rboltz*emiss*T**4\n",
    "    if loc == '+y':\n",
    "        T_y = grad(T,y,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "        return -k*T_y - h*T - Rboltz*emiss*T**4\n",
    "    if loc == '-z':\n",
    "        T_t = grad(T,t,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "        return T_t\n",
    "    if loc == '+z':\n",
    "        T_z = grad(T,z,create_graph=True,grad_outputs=torch.ones_like(T))[0]\n",
    "        q = 2*P*eta/torch.pi/r**2*torch.exp(-2*(torch.square(x-x0-v*t)+torch.square(y-y0))/r**2)*(t<=t_end)\n",
    "        return -k*T_z - h*T + q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7537fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "task = 'bareplate'\n",
    "x_max = np.array([40., 10.,  6.,  3.])\n",
    "x_min = np.array([ 0.,  0.,  0.,  0.])\n",
    "X_max = torch.tensor(x_max,dtype=torch.float).to(device)\n",
    "X_min = torch.tensor(x_min,dtype=torch.float).to(device)\n",
    "\n",
    "T_ref = 298.\n",
    "T_range = 3000.\n",
    "\n",
    "Cp = 0.5\n",
    "k = 0.01\n",
    "\n",
    "x0 = 5. # laser start x\n",
    "y0 = 5.\n",
    "r = 1.5 # beam radius\n",
    "v = 10 # speed\n",
    "t_end = 3. # laser end time\n",
    "\n",
    "h = 2e-5\n",
    "eta = 0.4\n",
    "P = 500\n",
    "Rboltz = 5.6704e-14\n",
    "emiss = 0.3\n",
    "rho = 8e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb3044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,x_max[3],31)\n",
    "\n",
    "# boundary points\n",
    "bound_x_neg,_ = sampling_uniform(1.,x_min,x_max,'-x',t)\n",
    "bound_x_pos,_ = sampling_uniform(1.,x_min,x_max,'+x',t)\n",
    "\n",
    "bound_y_neg,_ = sampling_uniform(1.,x_min,x_max,'-y',t)\n",
    "bound_y_pos,_ = sampling_uniform(1.,x_min,x_max,'+y',t)\n",
    "\n",
    "bound_z_neg,_ = sampling_uniform(1.,x_min,x_max,'-z',t)\n",
    "bound_z_pos,_ = sampling_uniform(1.,x_min,x_max,'+z',t)\n",
    "\n",
    "bound_z_pos_more = [] # more points for surface flux\n",
    "for ti in t:\n",
    "    if ti<t_end:\n",
    "        zi,_ = sampling_uniform(.25,\n",
    "                    [max(x0+ti*v-2*r,x_min[0]),max(x_min[1],y0-2*r),x_min[2]],\n",
    "                    [min(x0+ti*v+2*r,x_max[0]),min(x_max[1],y0+2*r),x_max[2]],\n",
    "                    '+z',[ti])\n",
    "        bound_z_pos_more.append(zi)\n",
    "\n",
    "bound_z_pos_more = np.vstack(bound_z_pos_more)\n",
    "bound_z_pos = np.vstack((bound_z_pos,bound_z_pos_more))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6ac462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, Loss: 3.758e+03, L_bc: 1.432e+04, L_ic: 7.046e+06, L_data: 0.000e+00, L_PDE: 1.620e+00, Time: 0.10\n",
      "It: 100, Loss: 8.167e+01, L_bc: 6.704e+01, L_ic: 2.597e+06, L_data: 0.000e+00, L_PDE: 1.051e-02, Time: 9.79\n",
      "It: 200, Loss: 5.045e+01, L_bc: 4.489e+01, L_ic: 1.569e+06, L_data: 0.000e+00, L_PDE: 6.850e-03, Time: 9.80\n",
      "It: 300, Loss: 3.494e+01, L_bc: 4.308e+01, L_ic: 9.668e+05, L_data: 0.000e+00, L_PDE: 9.698e-03, Time: 9.81\n",
      "It: 400, Loss: 2.588e+01, L_bc: 4.294e+01, L_ic: 6.057e+05, L_data: 0.000e+00, L_PDE: 1.108e-02, Time: 9.82\n",
      "It: 500, Loss: 2.048e+01, L_bc: 4.287e+01, L_ic: 3.904e+05, L_data: 0.000e+00, L_PDE: 1.106e-02, Time: 9.84\n",
      "It: 600, Loss: 1.722e+01, L_bc: 4.279e+01, L_ic: 2.608e+05, L_data: 0.000e+00, L_PDE: 1.032e-02, Time: 9.80\n",
      "It: 700, Loss: 1.520e+01, L_bc: 4.273e+01, L_ic: 1.808e+05, L_data: 0.000e+00, L_PDE: 9.345e-03, Time: 9.82\n",
      "It: 800, Loss: 1.392e+01, L_bc: 4.267e+01, L_ic: 1.298e+05, L_data: 0.000e+00, L_PDE: 8.404e-03, Time: 9.92\n",
      "It: 900, Loss: 1.307e+01, L_bc: 4.262e+01, L_ic: 9.633e+04, L_data: 0.000e+00, L_PDE: 7.598e-03, Time: 9.98\n",
      "It: 1000, Loss: 1.249e+01, L_bc: 4.259e+01, L_ic: 7.358e+04, L_data: 0.000e+00, L_PDE: 6.924e-03, Time: 9.98\n",
      "It: 1100, Loss: 1.208e+01, L_bc: 4.255e+01, L_ic: 5.762e+04, L_data: 0.000e+00, L_PDE: 6.400e-03, Time: 9.99\n",
      "It: 1200, Loss: 1.179e+01, L_bc: 4.252e+01, L_ic: 4.617e+04, L_data: 0.000e+00, L_PDE: 6.001e-03, Time: 9.99\n",
      "It: 1300, Loss: 1.157e+01, L_bc: 4.250e+01, L_ic: 3.771e+04, L_data: 0.000e+00, L_PDE: 5.732e-03, Time: 9.99\n",
      "It: 1400, Loss: 1.140e+01, L_bc: 4.247e+01, L_ic: 3.137e+04, L_data: 0.000e+00, L_PDE: 5.573e-03, Time: 10.00\n",
      "It: 1500, Loss: 1.127e+01, L_bc: 4.244e+01, L_ic: 2.649e+04, L_data: 0.000e+00, L_PDE: 5.514e-03, Time: 10.00\n",
      "It: 1600, Loss: 1.117e+01, L_bc: 4.241e+01, L_ic: 2.269e+04, L_data: 0.000e+00, L_PDE: 5.567e-03, Time: 10.01\n",
      "It: 1700, Loss: 1.109e+01, L_bc: 4.238e+01, L_ic: 1.972e+04, L_data: 0.000e+00, L_PDE: 5.735e-03, Time: 10.01\n",
      "It: 1800, Loss: 1.102e+01, L_bc: 4.235e+01, L_ic: 1.733e+04, L_data: 0.000e+00, L_PDE: 6.031e-03, Time: 10.01\n",
      "It: 1900, Loss: 1.096e+01, L_bc: 4.231e+01, L_ic: 1.544e+04, L_data: 0.000e+00, L_PDE: 6.506e-03, Time: 10.02\n",
      "It: 2000, Loss: 1.091e+01, L_bc: 4.226e+01, L_ic: 1.391e+04, L_data: 0.000e+00, L_PDE: 7.170e-03, Time: 10.02\n",
      "It: 2100, Loss: 1.087e+01, L_bc: 4.220e+01, L_ic: 1.271e+04, L_data: 0.000e+00, L_PDE: 8.127e-03, Time: 10.02\n",
      "It: 2200, Loss: 1.083e+01, L_bc: 4.214e+01, L_ic: 1.175e+04, L_data: 0.000e+00, L_PDE: 9.444e-03, Time: 10.02\n",
      "It: 2300, Loss: 1.079e+01, L_bc: 4.206e+01, L_ic: 1.102e+04, L_data: 0.000e+00, L_PDE: 1.131e-02, Time: 10.02\n",
      "It: 2400, Loss: 1.076e+01, L_bc: 4.197e+01, L_ic: 1.049e+04, L_data: 0.000e+00, L_PDE: 1.397e-02, Time: 10.02\n",
      "It: 2500, Loss: 1.072e+01, L_bc: 4.185e+01, L_ic: 1.014e+04, L_data: 0.000e+00, L_PDE: 1.782e-02, Time: 10.03\n",
      "It: 2600, Loss: 1.068e+01, L_bc: 4.172e+01, L_ic: 9.976e+03, L_data: 0.000e+00, L_PDE: 2.347e-02, Time: 10.03\n",
      "It: 2700, Loss: 1.065e+01, L_bc: 4.156e+01, L_ic: 9.989e+03, L_data: 0.000e+00, L_PDE: 3.192e-02, Time: 10.03\n",
      "It: 2800, Loss: 1.061e+01, L_bc: 4.136e+01, L_ic: 1.018e+04, L_data: 0.000e+00, L_PDE: 4.464e-02, Time: 10.03\n",
      "It: 2900, Loss: 1.056e+01, L_bc: 4.114e+01, L_ic: 1.053e+04, L_data: 0.000e+00, L_PDE: 6.369e-02, Time: 10.03\n",
      "It: 3000, Loss: 1.052e+01, L_bc: 4.088e+01, L_ic: 1.097e+04, L_data: 0.000e+00, L_PDE: 9.153e-02, Time: 10.03\n",
      "It: 3100, Loss: 1.047e+01, L_bc: 4.062e+01, L_ic: 1.141e+04, L_data: 0.000e+00, L_PDE: 1.298e-01, Time: 10.04\n",
      "It: 3200, Loss: 1.043e+01, L_bc: 4.037e+01, L_ic: 1.168e+04, L_data: 0.000e+00, L_PDE: 1.780e-01, Time: 10.04\n",
      "It: 3300, Loss: 1.039e+01, L_bc: 4.015e+01, L_ic: 1.168e+04, L_data: 0.000e+00, L_PDE: 2.329e-01, Time: 10.04\n",
      "It: 3400, Loss: 1.035e+01, L_bc: 3.997e+01, L_ic: 1.136e+04, L_data: 0.000e+00, L_PDE: 2.896e-01, Time: 10.04\n",
      "It: 3500, Loss: 1.031e+01, L_bc: 3.983e+01, L_ic: 1.082e+04, L_data: 0.000e+00, L_PDE: 3.449e-01, Time: 10.04\n",
      "It: 3600, Loss: 1.028e+01, L_bc: 3.971e+01, L_ic: 1.014e+04, L_data: 0.000e+00, L_PDE: 3.972e-01, Time: 10.04\n",
      "It: 3700, Loss: 1.025e+01, L_bc: 3.963e+01, L_ic: 9.397e+03, L_data: 0.000e+00, L_PDE: 4.454e-01, Time: 10.04\n",
      "It: 3800, Loss: 1.023e+01, L_bc: 3.956e+01, L_ic: 8.666e+03, L_data: 0.000e+00, L_PDE: 4.883e-01, Time: 10.04\n",
      "It: 3900, Loss: 1.021e+01, L_bc: 3.951e+01, L_ic: 7.970e+03, L_data: 0.000e+00, L_PDE: 5.254e-01, Time: 10.03\n",
      "It: 4000, Loss: 1.019e+01, L_bc: 3.947e+01, L_ic: 7.337e+03, L_data: 0.000e+00, L_PDE: 5.572e-01, Time: 10.04\n",
      "It: 4100, Loss: 1.017e+01, L_bc: 3.944e+01, L_ic: 6.773e+03, L_data: 0.000e+00, L_PDE: 5.825e-01, Time: 10.03\n",
      "It: 4200, Loss: 1.016e+01, L_bc: 3.941e+01, L_ic: 6.292e+03, L_data: 0.000e+00, L_PDE: 6.022e-01, Time: 10.04\n",
      "It: 4300, Loss: 1.015e+01, L_bc: 3.939e+01, L_ic: 5.878e+03, L_data: 0.000e+00, L_PDE: 6.174e-01, Time: 10.03\n",
      "It: 4400, Loss: 1.014e+01, L_bc: 3.937e+01, L_ic: 5.537e+03, L_data: 0.000e+00, L_PDE: 6.272e-01, Time: 10.03\n",
      "It: 4500, Loss: 1.013e+01, L_bc: 3.936e+01, L_ic: 5.256e+03, L_data: 0.000e+00, L_PDE: 6.344e-01, Time: 10.03\n",
      "It: 4600, Loss: 1.012e+01, L_bc: 3.933e+01, L_ic: 5.027e+03, L_data: 0.000e+00, L_PDE: 6.384e-01, Time: 10.04\n",
      "It: 4700, Loss: 1.011e+01, L_bc: 3.931e+01, L_ic: 4.853e+03, L_data: 0.000e+00, L_PDE: 6.384e-01, Time: 10.03\n",
      "It: 4800, Loss: 1.010e+01, L_bc: 3.929e+01, L_ic: 4.725e+03, L_data: 0.000e+00, L_PDE: 6.369e-01, Time: 10.04\n",
      "It: 4900, Loss: 1.009e+01, L_bc: 3.926e+01, L_ic: 4.630e+03, L_data: 0.000e+00, L_PDE: 6.315e-01, Time: 10.03\n",
      "It: 5000, Loss: 1.008e+01, L_bc: 3.922e+01, L_ic: 4.568e+03, L_data: 0.000e+00, L_PDE: 6.243e-01, Time: 10.03\n",
      "It: 5100, Loss: 1.006e+01, L_bc: 3.918e+01, L_ic: 4.544e+03, L_data: 0.000e+00, L_PDE: 6.153e-01, Time: 10.04\n",
      "It: 5200, Loss: 1.005e+01, L_bc: 3.914e+01, L_ic: 4.545e+03, L_data: 0.000e+00, L_PDE: 6.028e-01, Time: 10.03\n",
      "It: 5300, Loss: 1.003e+01, L_bc: 3.909e+01, L_ic: 4.573e+03, L_data: 0.000e+00, L_PDE: 5.879e-01, Time: 10.03\n",
      "It: 5400, Loss: 1.001e+01, L_bc: 3.903e+01, L_ic: 4.619e+03, L_data: 0.000e+00, L_PDE: 5.697e-01, Time: 10.04\n",
      "It: 5500, Loss: 9.995e+00, L_bc: 3.896e+01, L_ic: 4.679e+03, L_data: 0.000e+00, L_PDE: 5.488e-01, Time: 10.04\n",
      "It: 5600, Loss: 9.972e+00, L_bc: 3.889e+01, L_ic: 4.740e+03, L_data: 0.000e+00, L_PDE: 5.244e-01, Time: 10.04\n",
      "It: 5700, Loss: 9.947e+00, L_bc: 3.881e+01, L_ic: 4.810e+03, L_data: 0.000e+00, L_PDE: 4.978e-01, Time: 10.04\n",
      "It: 5800, Loss: 9.920e+00, L_bc: 3.873e+01, L_ic: 4.868e+03, L_data: 0.000e+00, L_PDE: 4.691e-01, Time: 10.04\n",
      "It: 5900, Loss: 9.892e+00, L_bc: 3.864e+01, L_ic: 4.896e+03, L_data: 0.000e+00, L_PDE: 4.402e-01, Time: 10.04\n",
      "It: 6000, Loss: 9.862e+00, L_bc: 3.854e+01, L_ic: 4.898e+03, L_data: 0.000e+00, L_PDE: 4.134e-01, Time: 10.04\n",
      "It: 6100, Loss: 9.831e+00, L_bc: 3.845e+01, L_ic: 4.847e+03, L_data: 0.000e+00, L_PDE: 3.904e-01, Time: 10.04\n",
      "It: 6200, Loss: 9.800e+00, L_bc: 3.835e+01, L_ic: 4.759e+03, L_data: 0.000e+00, L_PDE: 3.733e-01, Time: 10.04\n",
      "It: 6300, Loss: 9.768e+00, L_bc: 3.825e+01, L_ic: 4.631e+03, L_data: 0.000e+00, L_PDE: 3.625e-01, Time: 10.04\n",
      "It: 6400, Loss: 9.736e+00, L_bc: 3.814e+01, L_ic: 4.493e+03, L_data: 0.000e+00, L_PDE: 3.591e-01, Time: 10.04\n",
      "It: 6500, Loss: 9.702e+00, L_bc: 3.801e+01, L_ic: 4.352e+03, L_data: 0.000e+00, L_PDE: 3.627e-01, Time: 10.04\n",
      "It: 6600, Loss: 9.665e+00, L_bc: 3.787e+01, L_ic: 4.207e+03, L_data: 0.000e+00, L_PDE: 3.736e-01, Time: 10.03\n",
      "It: 6700, Loss: 9.623e+00, L_bc: 3.770e+01, L_ic: 4.074e+03, L_data: 0.000e+00, L_PDE: 3.891e-01, Time: 10.03\n",
      "It: 6800, Loss: 9.573e+00, L_bc: 3.748e+01, L_ic: 3.969e+03, L_data: 0.000e+00, L_PDE: 4.125e-01, Time: 10.03\n",
      "It: 6900, Loss: 9.510e+00, L_bc: 3.721e+01, L_ic: 3.880e+03, L_data: 0.000e+00, L_PDE: 4.444e-01, Time: 10.04\n",
      "It: 7000, Loss: 9.427e+00, L_bc: 3.683e+01, L_ic: 3.835e+03, L_data: 0.000e+00, L_PDE: 4.922e-01, Time: 10.03\n",
      "It: 7100, Loss: 9.309e+00, L_bc: 3.628e+01, L_ic: 3.844e+03, L_data: 0.000e+00, L_PDE: 5.690e-01, Time: 10.03\n",
      "It: 7200, Loss: 9.134e+00, L_bc: 3.544e+01, L_ic: 3.961e+03, L_data: 0.000e+00, L_PDE: 7.052e-01, Time: 10.04\n",
      "It: 7300, Loss: 8.885e+00, L_bc: 3.417e+01, L_ic: 4.236e+03, L_data: 0.000e+00, L_PDE: 9.455e-01, Time: 10.04\n",
      "It: 7400, Loss: 8.602e+00, L_bc: 3.267e+01, L_ic: 4.529e+03, L_data: 0.000e+00, L_PDE: 1.289e+00, Time: 10.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 7500, Loss: 8.355e+00, L_bc: 3.132e+01, L_ic: 4.582e+03, L_data: 0.000e+00, L_PDE: 1.637e+00, Time: 10.04\n",
      "It: 7600, Loss: 8.143e+00, L_bc: 3.025e+01, L_ic: 4.362e+03, L_data: 0.000e+00, L_PDE: 1.888e+00, Time: 10.04\n",
      "It: 7700, Loss: 7.951e+00, L_bc: 2.935e+01, L_ic: 4.039e+03, L_data: 0.000e+00, L_PDE: 2.051e+00, Time: 10.04\n",
      "It: 7800, Loss: 7.771e+00, L_bc: 2.858e+01, L_ic: 3.671e+03, L_data: 0.000e+00, L_PDE: 2.143e+00, Time: 10.04\n",
      "It: 7900, Loss: 7.598e+00, L_bc: 2.786e+01, L_ic: 3.326e+03, L_data: 0.000e+00, L_PDE: 2.200e+00, Time: 10.06\n",
      "It: 8000, Loss: 7.424e+00, L_bc: 2.717e+01, L_ic: 3.024e+03, L_data: 0.000e+00, L_PDE: 2.219e+00, Time: 10.03\n",
      "It: 8100, Loss: 7.239e+00, L_bc: 2.647e+01, L_ic: 2.810e+03, L_data: 0.000e+00, L_PDE: 2.205e+00, Time: 10.04\n",
      "It: 8200, Loss: 7.035e+00, L_bc: 2.571e+01, L_ic: 2.691e+03, L_data: 0.000e+00, L_PDE: 2.159e+00, Time: 10.04\n",
      "It: 8300, Loss: 6.796e+00, L_bc: 2.483e+01, L_ic: 2.651e+03, L_data: 0.000e+00, L_PDE: 2.087e+00, Time: 10.04\n",
      "It: 8400, Loss: 6.505e+00, L_bc: 2.373e+01, L_ic: 2.688e+03, L_data: 0.000e+00, L_PDE: 2.021e+00, Time: 10.03\n",
      "It: 8500, Loss: 6.114e+00, L_bc: 2.216e+01, L_ic: 2.790e+03, L_data: 0.000e+00, L_PDE: 2.020e+00, Time: 10.03\n",
      "It: 8600, Loss: 5.533e+00, L_bc: 1.970e+01, L_ic: 2.984e+03, L_data: 0.000e+00, L_PDE: 2.130e+00, Time: 10.04\n",
      "It: 8700, Loss: 4.639e+00, L_bc: 1.568e+01, L_ic: 3.276e+03, L_data: 0.000e+00, L_PDE: 2.549e+00, Time: 10.04\n",
      "It: 8800, Loss: 3.566e+00, L_bc: 1.056e+01, L_ic: 3.272e+03, L_data: 0.000e+00, L_PDE: 3.376e+00, Time: 10.04\n",
      "It: 8900, Loss: 2.764e+00, L_bc: 6.793e+00, L_ic: 2.963e+03, L_data: 0.000e+00, L_PDE: 3.968e+00, Time: 10.04\n",
      "It: 9000, Loss: 2.303e+00, L_bc: 4.602e+00, L_ic: 2.738e+03, L_data: 0.000e+00, L_PDE: 4.338e+00, Time: 10.04\n",
      "It: 9100, Loss: 2.060e+00, L_bc: 3.505e+00, L_ic: 2.540e+03, L_data: 0.000e+00, L_PDE: 4.480e+00, Time: 10.03\n",
      "It: 9200, Loss: 1.927e+00, L_bc: 2.924e+00, L_ic: 2.408e+03, L_data: 0.000e+00, L_PDE: 4.543e+00, Time: 10.03\n",
      "It: 9300, Loss: 1.842e+00, L_bc: 2.571e+00, L_ic: 2.323e+03, L_data: 0.000e+00, L_PDE: 4.566e+00, Time: 10.05\n",
      "It: 9400, Loss: 1.778e+00, L_bc: 2.291e+00, L_ic: 2.315e+03, L_data: 0.000e+00, L_PDE: 4.591e+00, Time: 10.03\n",
      "It: 9500, Loss: 1.726e+00, L_bc: 2.246e+00, L_ic: 2.263e+03, L_data: 0.000e+00, L_PDE: 4.431e+00, Time: 10.03\n",
      "It: 9600, Loss: 1.675e+00, L_bc: 2.058e+00, L_ic: 2.278e+03, L_data: 0.000e+00, L_PDE: 4.416e+00, Time: 10.03\n",
      "It: 9700, Loss: 1.628e+00, L_bc: 1.766e+00, L_ic: 2.396e+03, L_data: 0.000e+00, L_PDE: 4.507e+00, Time: 10.03\n",
      "It: 9800, Loss: 1.575e+00, L_bc: 1.869e+00, L_ic: 2.267e+03, L_data: 0.000e+00, L_PDE: 4.205e+00, Time: 10.04\n",
      "It: 9900, Loss: 1.516e+00, L_bc: 1.634e+00, L_ic: 2.377e+03, L_data: 0.000e+00, L_PDE: 4.192e+00, Time: 10.04\n",
      "It: 10000, Loss: 1.442e+00, L_bc: 1.661e+00, L_ic: 2.388e+03, L_data: 0.000e+00, L_PDE: 3.867e+00, Time: 10.04\n",
      "It: 10100, Loss: 1.346e+00, L_bc: 1.553e+00, L_ic: 2.520e+03, L_data: 0.000e+00, L_PDE: 3.578e+00, Time: 10.04\n",
      "It: 10200, Loss: 1.219e+00, L_bc: 1.470e+00, L_ic: 2.744e+03, L_data: 0.000e+00, L_PDE: 3.131e+00, Time: 10.04\n",
      "It: 10300, Loss: 1.070e+00, L_bc: 1.249e+00, L_ic: 3.041e+03, L_data: 0.000e+00, L_PDE: 2.727e+00, Time: 10.04\n",
      "It: 10400, Loss: 9.476e-01, L_bc: 1.016e+00, L_ic: 3.189e+03, L_data: 0.000e+00, L_PDE: 2.455e+00, Time: 10.04\n",
      "It: 10500, Loss: 8.566e-01, L_bc: 9.280e-01, L_ic: 3.093e+03, L_data: 0.000e+00, L_PDE: 2.189e+00, Time: 10.04\n",
      "It: 10600, Loss: 7.741e-01, L_bc: 6.872e-01, L_ic: 3.207e+03, L_data: 0.000e+00, L_PDE: 2.089e+00, Time: 10.04\n",
      "It: 10700, Loss: 6.910e-01, L_bc: 6.406e-01, L_ic: 3.155e+03, L_data: 0.000e+00, L_PDE: 1.808e+00, Time: 10.04\n",
      "It: 10800, Loss: 6.083e-01, L_bc: 5.207e-01, L_ic: 3.230e+03, L_data: 0.000e+00, L_PDE: 1.589e+00, Time: 10.04\n",
      "It: 10900, Loss: 5.268e-01, L_bc: 4.780e-01, L_ic: 3.314e+03, L_data: 0.000e+00, L_PDE: 1.298e+00, Time: 10.04\n",
      "It: 11000, Loss: 4.662e-01, L_bc: 4.254e-01, L_ic: 3.334e+03, L_data: 0.000e+00, L_PDE: 1.106e+00, Time: 10.04\n",
      "It: 11100, Loss: 4.285e-01, L_bc: 4.778e-01, L_ic: 3.103e+03, L_data: 0.000e+00, L_PDE: 9.259e-01, Time: 10.04\n",
      "It: 11200, Loss: 3.874e-01, L_bc: 3.006e-01, L_ic: 3.364e+03, L_data: 0.000e+00, L_PDE: 9.125e-01, Time: 10.04\n",
      "It: 11300, Loss: 3.575e-01, L_bc: 2.816e-01, L_ic: 3.302e+03, L_data: 0.000e+00, L_PDE: 8.179e-01, Time: 10.03\n",
      "It: 11400, Loss: 3.327e-01, L_bc: 3.235e-01, L_ic: 3.150e+03, L_data: 0.000e+00, L_PDE: 6.921e-01, Time: 10.04\n",
      "It: 11500, Loss: 3.094e-01, L_bc: 2.683e-01, L_ic: 3.232e+03, L_data: 0.000e+00, L_PDE: 6.462e-01, Time: 10.04\n",
      "It: 11600, Loss: 2.901e-01, L_bc: 2.468e-01, L_ic: 3.216e+03, L_data: 0.000e+00, L_PDE: 5.918e-01, Time: 10.05\n"
     ]
    }
   ],
   "source": [
    "iterations = 50000\n",
    "\n",
    "net = FNN([4,64,64,64,1],nn.Tanh(),in_tf=input_transform,out_tf=output_transform)\n",
    "net.to(device)\n",
    "\n",
    "point_sets,flags = generate_points([],[])\n",
    "\n",
    "l_history = train(net,PDE,BC,point_sets,flags,iterations,lr=5e-4,info_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474cc859",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'../model/{}.pt'.format(task))\n",
    "np.save('../model/{}.npy'.format(task),l_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef32e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
